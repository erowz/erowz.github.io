I"6<h1 id="분석-도구">분석 도구</h1>

<ul>
  <li>프로그래밍 언어 파이썬(<a href="https://www.python.org/">Python</a>)</li>
  <li>파이썬의 데이터 분석 패키지 판다스(<a href="https://pandas.pydata.org/">Pandas</a>)</li>
  <li>파이썬의 머신러닝&amp;인공지능 라이브러리인 싸이킷런(<a href="https://willnfate.tistory.com/scikit-learn.org">scikit-learn</a>)</li>
</ul>

<h1 id="데이터-분석-과정">데이터 분석 과정</h1>

<ol>
  <li>데이터 로딩 : read_csv</li>
  <li>시각화 및 가설 : <a href="https://seaborn.pydata.org/index.html">seaborn</a>, <a href="https://matplotlib.org/">matplotlib</a></li>
  <li>전처리(Preprocessing) : <a href="https://ko.wikipedia.org/wiki/%EA%B2%B0%EC%A0%95_%ED%8A%B8%EB%A6%AC_%ED%95%99%EC%8A%B5%EB%B2%95">DecisionTree</a>를 사용하기 위해서 데이터를 숫자로 가공</li>
  <li>데이터 준비 : feature와 label을 사용해 X_train, X_test, y_train 데이터 생성</li>
  <li>학습(Train) : DecisionTree를 사용해 데이터 학습(fit) 및 예측(predict)</li>
  <li>반영(Submission) : 제출용 데이터 호출해서 결과값 저장</li>
  <li>출력 : csv 파일로 저장 .to_csv</li>
</ol>

<blockquote>
  <p><strong>REF</strong><br />
<a href="https://datascienceschool.net/view-notebook/4c2d5ff1caab4b21a708cc662137bc65/">Seaborn을 사용한 데이터 분포 시각화</a></p>
</blockquote>

<h1 id="분석-알고리즘">분석 알고리즘</h1>

<blockquote>
  <p><strong>REF</strong><br />
<a href="http://www.dodomira.com/2016/08/19/frequently_used_analyitic_method/">대표적인 데이터 분석 테크닉 30가지</a></p>
</blockquote>

<h1 id="분석-성능-향상">분석 성능 향상</h1>

<ol>
  <li>문제 정의 및 그에 맞는 <a href="https://ko.wikipedia.org/wiki/%EA%B2%B0%EC%A0%95_%ED%8A%B8%EB%A6%AC_%ED%95%99%EC%8A%B5%EB%B2%95">DecisionTree</a> 선택</li>
  <li>알고리즘 정의 - Random Forest</li>
  <li>탐험적 데이터 분석 - 시각화 분석, 도메인 지식 기반 분석</li>
</ol>

<h2 id="탐험적-데이터-분석">탐험적 데이터 분석</h2>

<blockquote>
  <p><strong>REF</strong><br />
03-bike-sharing-demand.pdf</p>
</blockquote>

<ol>
  <li>알고리즘 업데이트 가능 여부</li>
  <li>데이터적으로 가공 가능 여부</li>
</ol>

<h3 id="데이터-분석">데이터 분석</h3>

<ul>
  <li>가설
    <ul>
      <li>데이터를 보고 가설 수립</li>
    </ul>
  </li>
  <li>검증
    <ul>
      <li>엑셀 : pivot table</li>
      <li>python : decision tree</li>
    </ul>
  </li>
  <li>예측
    <ul>
      <li>검증을 통해 가설이 맞다면 예측한 뒤 사용</li>
    </ul>
  </li>
</ul>

<h3 id="model-validation">Model Validation</h3>
<ul>
  <li>테스트를 하기 전에 검증을 하는 과정</li>
</ul>

<h4 id="hold-out-validation">Hold-out Validation</h4>
<ul>
  <li>train data를 8:2(fit:predict)로 나누어 분석</li>
  <li>한번만 나누어 작업하므로 빠르지만 정확도가 떨어질 우려가 있다</li>
</ul>

<h4 id="cross-validation">Cross Validation</h4>
<ul>
  <li>결과가 좋지 않은 경우 test set을 여러 개 생성해서 분석</li>
  <li>1/n로 데이터를 나누어 하나씩 validation하여 n번 looping해서 정확도를 높여준다</li>
  <li>실행 속도가 느리지만 정확도를 높힐 수 있다</li>
  <li>각각의 데이터 결과를 모두 비교/분석하여 결과 도출</li>
</ul>

<h3 id="evaludation-metric-for-regression">Evaludation Metric for regression</h3>
<ul>
  <li>regression : 정답에 최대한 가깝게 예측하는 게 좋다</li>
  <li>정확도를 측정하는 방법</li>
  <li>정답(actural, a)과 예측값(predict, p)의 차이를 비교해서 이 수치가 0에 가까울 수록 좋은 결과</li>
  <li>그외 : precesion, recall</li>
</ul>

<ol>
  <li>Mean Absolute Error(MAE)
    <ul>
      <li>절대값으로 계산</li>
      <li>에측값과 실제값의 평균적인 차이</li>
      <li>|$p-a$|</li>
    </ul>
  </li>
  <li>Mean Squared Error(MSE)
    <ul>
      <li>제곱을 하여 계산</li>
      <li>오차를 제곱하면 그 값이 차이가 커지므로 더 많이 틀릴 수록 패널티를 적용하는 개념이 됨</li>
      <li>$(p-a)^2$</li>
    </ul>
  </li>
  <li>Root Mean Squared Error(RMSE)
    <ul>
      <li>루트를 씌워서 현실값과 유사하게 계산</li>
      <li>현실값과 유사하게 맞춰 직관적으로 판단하기 용이</li>
      <li>$\sqrt{({p - a})^2}$</li>
    </ul>
  </li>
</ol>

<h3 id="online-evaluation">Online Evaluation</h3>
<ul>
  <li>회사(또는 부서, 서비스)에서 일반적으로 사용하는 온라인 지표(online metric)과 가장 일치하는 오프라인 지표를 사용</li>
</ul>

<h3 id="root-mean-squared-logarithmic-error-rmsle">Root Mean Squared Logarithmic Error? (RMSLE)</h3>
<ul>
  <li>RMSE와 유사하게 계산을 하지만 사전에 log를 씌워서 계산</li>
  <li>값이 커지는 부분을 완화시켜주기 위한 처리 : 값이 튀는 데이터가 많은 경우 사용</li>
</ul>

<h1 id="정확도-높이기">정확도 높이기</h1>

<h2 id="1-count-값-outlier">1. count 값 outlier</h2>
<ul>
  <li>distplot으로 <code class="highlighter-rouge">train['count']</code>를 보니 왼쪽으로 치우쳐진 꼬리가 긴 형태
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="o">.</span><span class="n">displot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="p">[</span><span class="s">'count'</span><span class="p">],</span> <span class="n">hist</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div>    </div>
  </li>
  <li>count 값에 log 적용
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">label</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
<span class="o">...</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span>
</code></pre></div>    </div>
  </li>
  <li>결과값이 확연히 좋아짐</li>
</ul>

<h2 id="2-registerd--casual">2. registerd / casual</h2>
<ul>
  <li>hour로 시각화해보면 둘의 양상이 다르다</li>
  <li>각각 중요한 변수가 다를 것이다</li>
  <li>둘을 각각 모델링해서 둘의 결과를 산출해서 더해서 count를 구해보자</li>
</ul>

<ol>
  <li>y_train 분리
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_train_reg</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s">'registered'</span><span class="p">]</span>
<span class="n">y_train_cas</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s">'casual'</span><span class="p">]</span>
</code></pre></div>    </div>
  </li>
  <li>model, fit(), predict()를 각각 따로 처리</li>
  <li>결과 합산
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">predict</span> <span class="o">=</span> <span class="n">predict_reg</span> <span class="o">+</span> <span class="n">predict_cas</span>
</code></pre></div>    </div>
  </li>
</ol>

<ul>
  <li>count log 결과보다는 정확도가 떨어지지만 둘을 함께 적용하면 더 좋아질 거라 예상해봄</li>
</ul>

<h2 id="3-hyper-parameter-tuning">3. Hyper-parameter Tuning</h2>
<ul>
  <li>model의 다양한 파라미터 값을 설정해서 튜닝</li>
  <li>hyper-parameter : 사람이 직접 조정하는 파라미터
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">bootstrap</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s">'mse'</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                    <span class="n">max_features</span><span class="o">=</span><span class="s">'auto'</span><span class="p">,</span> <span class="n">max_leaf_nodes</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                    <span class="n">min_impurity_decrease</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">min_impurity_split</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                    <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                    <span class="n">min_weight_fraction_leaf</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="s">'warn'</span><span class="p">,</span>
                    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">oob_score</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">37</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                    <span class="n">warm_start</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div>    </div>
  </li>
</ul>

<h3 id="randomforestregressor-parameter">RandomForestRegressor parameter</h3>

<ul>
  <li>n_estimators
    <ul>
      <li>decisionTree를 몇 개 쌓을 것인지 지정</li>
      <li>클 수록 좋지만 무작정 높인다고 결과가 좋아지는 것이 아님 (로그 그래프 형태로 성능 향상)</li>
      <li>10 또는 100(최신 버전)</li>
    </ul>
  </li>
  <li>max_features
    <ul>
      <li>bagging(데이터셋을 여러개 구성하고 여러 개의 모델 사용)에서 각 트리 하나당 몇 개의 변수를 선택할 지 지정</li>
      <li>eg. 30 (각 트리당 30개의 변수 지정), 0.1(비율로 지정)</li>
      <li>0.1 간격으로 0~1 사이의 값을 테스트해보자</li>
    </ul>
  </li>
  <li>max_depth
    <ul>
      <li>몇 번의 질문을 할 것인지 설정</li>
      <li>기본 설정으로 모델이 몇 개의 트리를 설정했는지 확인해서 그 값으로부터 시작해서 설정 조절</li>
    </ul>
  </li>
  <li>min_samples_leaf
    <ul>
      <li>Decision Tree의 노드에서 더 질문을 할지 말지 여부를 결정</li>
      <li>질문을 진해할 최소 데이터 개수 지정. eg. 10으로 지정 시 10개의 데이터가 쌓이면 질문 중단</li>
    </ul>
  </li>
</ul>

<h3 id="파라미터-설정-방법">파라미터 설정 방법</h3>

<h4 id="1-grid-search">1) Grid Search</h4>
<ul>
  <li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html">scikit-learn GridSearchCV</a></li>
  <li>가장 좋은 설정값을 찾는 과정</li>
  <li>테스트가 많아질 수록 시간이 많이 걸리는 단점</li>
</ul>

<ol>
  <li>max_features와 max_depth의 적정값을 찾아서 설정
    <ul>
      <li>for문 돌려서 다양한 값 적용해서 cross_val_predict로 score 게산해서 확인</li>
    </ul>
  </li>
  <li>n_estimators 설정</li>
</ol>

<h4 id="2-random-search">2) Random Search</h4>
<ul>
  <li>넣어주는 파라미터를 랜덤하게 설정오는 방법</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">max_depth</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>

<span class="k">for</span> <span class="o">..</span> <span class="p">:</span>
  <span class="c1"># 모델 생성
</span>  <span class="c1"># 점수 산출
</span></code></pre></div></div>

<h4 id="3-coerse--fine-search">3) Coerse &amp; Fine Search</h4>
<ul>
  <li>랜덤 서치 2번 실행
    <ol>
      <li>대략의 범위로 1차 랜덤 서치 실행</li>
      <li>1차 서치에서 산출한 값으로 범위를 좁혀서 2차 실행</li>
    </ol>
  </li>
</ul>

<h1 id="빅데이터-분석-주요사항">빅데이터 분석 주요사항</h1>

<ol>
  <li>문제 분석 : 무엇을 맞추고 싶은 지 값을 먼저 결정</li>
  <li>알고리즘 선택</li>
  <li>데이터 준비 : 일반 데이터의 경우 8:2로 train/test 데이터 구성</li>
  <li>데이터 시각화 : 데이터 분포 파악</li>
  <li>데이터 전처리 : 빈값 채우기, 숫자로 변경</li>
  <li>성능 향상</li>
  <li>튜닝</li>
  <li>검증</li>
  <li>배포</li>
</ol>

<p>모델 선택</p>
<ul>
  <li>기본부터 시작 : Decision Tree</li>
  <li>svm 알고리즘 : 분류에 좋대</li>
</ul>
:ET