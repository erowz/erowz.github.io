---
title: 통계학 - 확률과 통계
category: Stats
tags: [bigdata, statistics, stats, 통계학, 확률변수, 확률분포]
description: 제대로 시작하는 기초 통계학 강의 노트
published : false
---

# 확률과 의사결정
- 통계의 목적 : 표본 조사 > 모수(parameter) 추정 > 모집단의 특징 분석
- 표본에서 모수를 추정하는 이유
  1. 모집단을 대상으로 하는 조사가 불가능
  2. 시간과 비용 등의 물리적 한계
- 표본에서 모수 추정해서 발생하는 오차 해결 방법
  - 통계량이 모수와 일치할 확률을 나타냄으로써 해결
  - 통계량이 맞을 확률을 같이 제시하여 그 통계량이 의미가 있도록 하는 것

## 확률(probability)
- 아무리 정교하게 분석된 통계자료라 할 지라도 100% 맞을 수 없으므로 그 결과를 확률과 함께 표현한다
- 통계의 결과가 전혀 맞지 않는 경우(0%), 모두 맞을 확률(100%)
- 일정 조건 하에서 동일한 실험을 지속적으로 N회 반복했을 때, 사건 A가 n번 발생할 확률 P

$$
P(A)=\frac{n(A)}{N}
$$

n(A) : 사건 A가 발생하는 경우의 수, N : 전체 경우의 수

### 확률의 조건
- 0 ~ 1 사이의 값
- 모든 사건에 대한 확률의 합 : 1

    $$
    \sum_{i=1}^{n}P(E_i) = 1
    $$

    ($E$ : 사건(Event), $i$ : 시행 횟수, $P$ : 확률)

### 확률의 덧셈법칙(addition rule of probability)
- A, B 두 사건이 있을 때 A 또는 B 사건이 일어날 확률
  
  1. 중복이 있는 경우 : A의 확률 + B의 확률 - 공통으로 발생하는 부분의 확률
  
    $$
    P(A \cup B) = P(A) + P(B) - P(A \cap B)
    $$

  2. 배반 사건의 경우 : A의 확률 + B의 확률

    $$
    P(A \cup B) = P(A) + P(B)
    $$

### 조건부 확률(conditional probability)
- A가 먼저 발생한 상황 하에 B가 발생할 확률

    $$
    P(B|A) = \frac{P(B \cap A)}{P(A)}
    $$

    이를 정리하면

    $$
    P(B \cap A) = P(A) \cdot P(B|A)
    $$

# 확률변수의 기대값과 분산

## 확률변수의 기대값(expected value)
- 통계학에서 기대값은 평균과 같은 의미로 사용됨
- 사건에서 발생하는 해당 값과 그 사건이 발생할 확률을 곱해서 모두 더한 값
- 수식
  - 확률 : 
$$
\sum_{i=1}^{n}P(E_i) = 1
$$

  - 기대값 : 
$$
E(X)=\sum xP(x)
$$

- eg. 주사위를 던졌을 때의 기대값

$$
1 \times \frac{1}{6} + 2 \times \frac{1}{6} + 3 \times \frac{1}{6} + 4 \times \frac{1}{6} + 5 \times \frac{1}{6} + 6 \times \frac{1}{6} \\
= \frac{1+2=3+4+5+6}{6} = 3.5
$$

### 기대값의 성질
- a,b가 상수, X,Y가 확률변수일 때 다음이 성립 (E : 기대값)

1. $E(a) = a$ : *상수에 대한 기대값은 상수*
2. $E(aX) = aE(X)$ : *상수와 확률변수를 곱했을 때 상수는 밖으로 나옴*
3. $E(aX \pm b) = aE(X) \pm b$ : *상수를 밖으로 뺄 수 있다*
4. $E(aX \pm bY) = aE(X) \pm bE(Y)$ : *상수를 밖으로 뺄 수 있다*
5. $E(XY) = E(X)E(Y)$, X와 Y는 확률적으로 독립

## 확률변수의 분산

### 분산(variance)
- 기대값의 특성을 나태나는 값
- 확률변수들이 기대값으로부터 벗어나는 정도를 나타냄
- 기대값과 어느 정도 차이가 있는지를 표현
- 확률변수와 기대값($\mu$)의 차이를 구한 후 제곱하고, 해당 사건의 확률($P(x)$)을 곱한 후 모두 더해서 구한다

$$
Var(X) = E(X-\mu)^2 = \sum (X-\mu)^2P(X)
$$

#### 분산의 성질
- a,b가 상수, X,Y가 확률변수일 때 다음이 성립

1. $Var(a) = 0$ : *상수에 대한 분산은 0이다*
2. $Var(aX) = a^2Var(X)$ : *상수가 밖으로 나오면서 분산은 제곱의 합이므로 상수 제곱으로 나온다*
3. $Var(X+Y) = Var(X) + Var(Y) + 2Cov(X,Y)$ : *공분산이 있으면 더해준다*  
    $Var(X+Y) = Var(X) + Var(Y)$ , X와 Y는 확률적으로 독립
4. $Var(X-Y) = Var(X) + Var(Y) - 2Cov(X,Y)$ : *분산은 제곱이므로 분리하면 +가 된다. 공분산은 빼준다*  
    $Var(X+Y) = Var(X) + Var(Y)$ , X와 Y는 확률적으로 독립

### 확률변수의 표준편차
- 분산($\sigma^2$)의 제곱근

$$
\sigma = \sqrt{E(X-\mu)^2} = \sqrt{\sum(X - \mu)^2 P(X)}
$$


### 확률변수의 기대값과 분산 예제
![](/assets/images/stats/stats-book/random_variable_eg.png)  

- 확률변수의 기대값

$$E(X)= \sum xP(x)$$

  - A의 기대값 = 300 X 0.58 + 150 X 0.87 + 0 X 0.55 + (-100) X 0.05 = 299.5
  - B의 기대값 = 300 X 0.65 + 150 X 0.51 + 0 X 0.45 + (-100) X 0.05 = 266.5

- 확률변수의 분산 : 기대값을 먼저 구해야 계산 가능

$$Var(X) = E(X - \mu)^2= \sum(X - \mu)^2 P(X)$$

  - A의 분산 $ = (300 - 299.5)^2 \times 0.58 + (150 - 299.5)^2 \times 0.87$  
    $ \qquad \qquad + (0 - 299.5)^2 \times 0.55 + ((-100) - 299.5)^2 \times 0.05$  
    $ \qquad \quad = 76,760.0125$
  - B의 분산 $ = (300 - 266.5)^2 \times 0.65 + (150 - 266.5)^2 \times 0.51$  
    $ \qquad \qquad + (0 - 266.5)^2 \times 0.45 + ((-100) - 266.5)^2 \times 0.05$  
    $ \qquad \quad = 46,327.435$ 

- 결과 분석
  - 기대값 : A의 인센티브가 B의 것보다 약 30만큼 높게 기대됨
  - 분산 : A의 분산이 더 크므로 B보다 불안정하다고 볼 수 있다
  - A : 우승 확률이 조금 떨어지고 기대값이 높다
  - B : 기대값이 적지만 조금 더 안정적이고 우승 확률이 높다

- 선택 결과 : 우승을 노리고 있으므로 B를 선택

